{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d4b9fa8",
   "metadata": {},
   "source": [
    "## 1. Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad08d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Audio processing\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration\n",
    "SAMPLE_RATE = 22050  # Standard sample rate\n",
    "DURATION = 5.0       # Fixed audio duration in seconds\n",
    "N_MFCC = 13          # Number of MFCC coefficients\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = 'data/raw'\n",
    "OUTPUT_DIR = 'output'\n",
    "CLASSES = ['car', 'tram']\n",
    "\n",
    "print(\"Libraries loaded successfully!\")\n",
    "print(f\"Sample Rate: {SAMPLE_RATE} Hz\")\n",
    "print(f\"Audio Duration: {DURATION} seconds\")\n",
    "print(f\"Classes: {CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43169ec2",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "Load audio files from the `data/raw/car` and `data/raw/tram` folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105e5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_files(data_dir, classes, sr=SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "    Load all audio files from class folders.\n",
    "    \n",
    "    Returns:\n",
    "        audio_data: list of (audio_array, sample_rate, filename)\n",
    "        labels: list of class labels\n",
    "    \"\"\"\n",
    "    audio_data = []\n",
    "    labels = []\n",
    "    \n",
    "    for class_name in classes:\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        \n",
    "        if not os.path.exists(class_dir):\n",
    "            print(f\"Warning: Directory {class_dir} does not exist!\")\n",
    "            continue\n",
    "        \n",
    "        files = [f for f in os.listdir(class_dir) \n",
    "                 if f.endswith(('.wav', '.mp3', '.flac', '.ogg', '.m4a'))]\n",
    "        \n",
    "        print(f\"Loading {len(files)} files from '{class_name}' folder...\")\n",
    "        \n",
    "        for filename in files:\n",
    "            filepath = os.path.join(class_dir, filename)\n",
    "            try:\n",
    "                # Load audio file\n",
    "                audio, _ = librosa.load(filepath, sr=sr)\n",
    "                audio_data.append((audio, sr, filename))\n",
    "                labels.append(class_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "    \n",
    "    return audio_data, labels\n",
    "\n",
    "# Load the data\n",
    "audio_data, labels = load_audio_files(DATA_DIR, CLASSES)\n",
    "\n",
    "print(f\"\\nTotal samples loaded: {len(audio_data)}\")\n",
    "print(f\"Class distribution:\")\n",
    "for cls in CLASSES:\n",
    "    count = labels.count(cls)\n",
    "    print(f\"  - {cls}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ae5c31",
   "metadata": {},
   "source": [
    "## 3. Normalization\n",
    "\n",
    "Apply audio normalization:\n",
    "1. **Peak normalization**: Scale audio to [-1, 1] range\n",
    "2. **Pad/Truncate**: Ensure all audio clips are exactly 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209e1e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_audio(audio):\n",
    "    \"\"\"\n",
    "    Apply peak normalization to audio signal.\n",
    "    Scales the audio to have maximum amplitude of 1.0\n",
    "    \"\"\"\n",
    "    max_val = np.max(np.abs(audio))\n",
    "    if max_val > 0:\n",
    "        return audio / max_val\n",
    "    return audio\n",
    "\n",
    "def pad_or_truncate(audio, sr, duration=DURATION):\n",
    "    \"\"\"\n",
    "    Pad with zeros or truncate audio to fixed duration.\n",
    "    \"\"\"\n",
    "    target_length = int(sr * duration)\n",
    "    \n",
    "    if len(audio) > target_length:\n",
    "        # Truncate to target length\n",
    "        return audio[:target_length]\n",
    "    elif len(audio) < target_length:\n",
    "        # Pad with zeros\n",
    "        padding = target_length - len(audio)\n",
    "        return np.pad(audio, (0, padding), mode='constant')\n",
    "    return audio\n",
    "\n",
    "def preprocess_audio(audio_data):\n",
    "    \"\"\"\n",
    "    Apply normalization and padding to all audio samples.\n",
    "    \"\"\"\n",
    "    processed_audio = []\n",
    "    \n",
    "    for audio, sr, filename in audio_data:\n",
    "        # Step 1: Peak normalization\n",
    "        audio_norm = normalize_audio(audio)\n",
    "        \n",
    "        # Step 2: Pad or truncate to fixed duration\n",
    "        audio_fixed = pad_or_truncate(audio_norm, sr)\n",
    "        \n",
    "        processed_audio.append((audio_fixed, sr, filename))\n",
    "    \n",
    "    return processed_audio\n",
    "\n",
    "# Preprocess all audio\n",
    "processed_audio = preprocess_audio(audio_data)\n",
    "\n",
    "print(f\"Preprocessing complete!\")\n",
    "print(f\"All audio clips normalized and padded/truncated to {DURATION} seconds\")\n",
    "print(f\"Sample length: {len(processed_audio[0][0])} samples ({DURATION}s at {SAMPLE_RATE}Hz)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f5010f",
   "metadata": {},
   "source": [
    "## 4. Feature Extraction\n",
    "\n",
    "Extract audio features for classification:\n",
    "- **MFCCs** (13 coefficients): Captures timbral characteristics\n",
    "- **Spectral Centroid**: \"Brightness\" of the sound\n",
    "- **Zero Crossing Rate (ZCR)**: Noisiness indicator\n",
    "- **RMS Energy**: Volume/loudness\n",
    "- **Spectral Rolloff**: Frequency distribution\n",
    "\n",
    "For each feature, we compute **mean** and **standard deviation** across time frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a9664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio, sr, n_mfcc=N_MFCC):\n",
    "    \"\"\"\n",
    "    Extract audio features from a single audio sample.\n",
    "    \n",
    "    Returns:\n",
    "        feature_vector: numpy array of aggregated features\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # 1. MFCCs (13 coefficients x 2 stats = 26 features)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
    "    features.extend(np.mean(mfccs, axis=1))  # Mean of each MFCC\n",
    "    features.extend(np.std(mfccs, axis=1))   # Std of each MFCC\n",
    "    \n",
    "    # 2. Spectral Centroid (2 features)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
    "    features.append(np.mean(spectral_centroid))\n",
    "    features.append(np.std(spectral_centroid))\n",
    "    \n",
    "    # 3. Zero Crossing Rate (2 features)\n",
    "    zcr = librosa.feature.zero_crossing_rate(audio)[0]\n",
    "    features.append(np.mean(zcr))\n",
    "    features.append(np.std(zcr))\n",
    "    \n",
    "    # 4. RMS Energy (2 features)\n",
    "    rms = librosa.feature.rms(y=audio)[0]\n",
    "    features.append(np.mean(rms))\n",
    "    features.append(np.std(rms))\n",
    "    \n",
    "    # 5. Spectral Rolloff (2 features)\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]\n",
    "    features.append(np.mean(spectral_rolloff))\n",
    "    features.append(np.std(spectral_rolloff))\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "def extract_all_features(processed_audio):\n",
    "    \"\"\"\n",
    "    Extract features from all audio samples.\n",
    "    \"\"\"\n",
    "    feature_list = []\n",
    "    \n",
    "    for i, (audio, sr, filename) in enumerate(processed_audio):\n",
    "        features = extract_features(audio, sr)\n",
    "        feature_list.append(features)\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(processed_audio)} files...\")\n",
    "    \n",
    "    return np.array(feature_list)\n",
    "\n",
    "# Extract features\n",
    "print(\"Extracting features...\")\n",
    "X = extract_all_features(processed_audio)\n",
    "\n",
    "# Create feature names for reference\n",
    "feature_names = []\n",
    "for i in range(N_MFCC):\n",
    "    feature_names.append(f'mfcc_{i+1}_mean')\n",
    "for i in range(N_MFCC):\n",
    "    feature_names.append(f'mfcc_{i+1}_std')\n",
    "feature_names.extend(['spectral_centroid_mean', 'spectral_centroid_std',\n",
    "                      'zcr_mean', 'zcr_std',\n",
    "                      'rms_mean', 'rms_std',\n",
    "                      'spectral_rolloff_mean', 'spectral_rolloff_std'])\n",
    "\n",
    "print(f\"\\nFeature extraction complete!\")\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Number of features per sample: {len(feature_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79977bd",
   "metadata": {},
   "source": [
    "## 5. Data Split and Scaling\n",
    "\n",
    "- Split data into training (80%) and testing (20%) sets\n",
    "- Apply StandardScaler to normalize features (important for SVM!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2518099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to numeric values\n",
    "label_mapping = {'car': 0, 'tram': 1}\n",
    "y = np.array([label_mapping[label] for label in labels])\n",
    "\n",
    "print(f\"Labels encoded: {label_mapping}\")\n",
    "print(f\"Label distribution: car={np.sum(y==0)}, tram={np.sum(y==1)}\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y  # Maintain class balance\n",
    ")\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"  Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"  Testing set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Feature scaling using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)  # Use same scaler fitted on training data\n",
    "\n",
    "print(f\"\\nFeatures scaled using StandardScaler\")\n",
    "print(f\"  Training mean (should be ~0): {X_train_scaled.mean():.6f}\")\n",
    "print(f\"  Training std (should be ~1): {X_train_scaled.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1b18fb",
   "metadata": {},
   "source": [
    "## 6. SVM Training\n",
    "\n",
    "Train a Support Vector Machine classifier with RBF kernel.\n",
    "We use GridSearchCV to find optimal hyperparameters (C and gamma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96718c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SVM with RBF kernel\n",
    "svm_model = SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "# Hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "print(\"Training SVM with GridSearchCV for hyperparameter tuning...\")\n",
    "print(f\"Parameter grid: {param_grid}\")\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    svm_model, \n",
    "    param_grid, \n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36822c71",
   "metadata": {},
   "source": [
    "## 7. Evaluation\n",
    "\n",
    "Evaluate the trained model on the test set using:\n",
    "- **Accuracy**: Overall correctness\n",
    "- **Precision**: How many predicted positives are actually positive\n",
    "- **Recall**: How many actual positives were correctly identified\n",
    "- **F1-Score**: Harmonic mean of precision and recall\n",
    "- **Confusion Matrix**: Detailed breakdown of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39a75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"MODEL EVALUATION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nAccuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(y_test, y_pred, target_names=CLASSES))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5be982",
   "metadata": {},
   "source": [
    "## 8. Visualizations\n",
    "\n",
    "Create visualizations for the report:\n",
    "1. Sample waveforms from each class\n",
    "2. Sample spectrograms\n",
    "3. Confusion matrix heatmap\n",
    "4. Feature importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d4c55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=CLASSES, yticklabels=CLASSES)\n",
    "plt.title('Confusion Matrix - SVM Classifier')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'confusion_matrix.png'), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Confusion matrix saved to {OUTPUT_DIR}/confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b218df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sample waveforms from each class\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "for idx, class_name in enumerate(CLASSES):\n",
    "    # Find first sample of this class\n",
    "    class_idx = labels.index(class_name)\n",
    "    audio, sr, filename = processed_audio[class_idx]\n",
    "    \n",
    "    # Waveform\n",
    "    axes[idx, 0].plot(np.linspace(0, DURATION, len(audio)), audio, color='blue', linewidth=0.5)\n",
    "    axes[idx, 0].set_title(f'{class_name.upper()} - Waveform')\n",
    "    axes[idx, 0].set_xlabel('Time (s)')\n",
    "    axes[idx, 0].set_ylabel('Amplitude')\n",
    "    axes[idx, 0].set_ylim(-1, 1)\n",
    "    \n",
    "    # Spectrogram\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
    "    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz', ax=axes[idx, 1])\n",
    "    axes[idx, 1].set_title(f'{class_name.upper()} - Spectrogram')\n",
    "    axes[idx, 1].set_xlabel('Time (s)')\n",
    "    axes[idx, 1].set_ylabel('Frequency (Hz)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'waveforms_spectrograms.png'), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Waveforms and spectrograms saved to {OUTPUT_DIR}/waveforms_spectrograms.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fedbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature statistics comparison between classes\n",
    "df_features = pd.DataFrame(X, columns=feature_names)\n",
    "df_features['class'] = labels\n",
    "\n",
    "# Plot mean feature values per class for key features\n",
    "key_features = ['mfcc_1_mean', 'mfcc_2_mean', 'spectral_centroid_mean', \n",
    "                'zcr_mean', 'rms_mean', 'spectral_rolloff_mean']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(key_features):\n",
    "    df_features.boxplot(column=feature, by='class', ax=axes[i])\n",
    "    axes[i].set_title(feature)\n",
    "    axes[i].set_xlabel('Class')\n",
    "    axes[i].set_ylabel('Value')\n",
    "\n",
    "plt.suptitle('Feature Distribution by Class', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'feature_distribution.png'), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Feature distribution plot saved to {OUTPUT_DIR}/feature_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d298db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=\"*60)\n",
    "print(\"PROJECT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDataset:\")\n",
    "print(f\"  - Total samples: {len(audio_data)}\")\n",
    "print(f\"  - Car samples: {labels.count('car')}\")\n",
    "print(f\"  - Tram samples: {labels.count('tram')}\")\n",
    "print(f\"  - Audio duration: {DURATION} seconds\")\n",
    "print(f\"  - Sample rate: {SAMPLE_RATE} Hz\")\n",
    "\n",
    "print(f\"\\nFeatures:\")\n",
    "print(f\"  - Total features: {len(feature_names)}\")\n",
    "print(f\"  - MFCCs: {N_MFCC} coefficients (mean + std)\")\n",
    "print(f\"  - Spectral features: centroid, ZCR, RMS, rolloff\")\n",
    "\n",
    "print(f\"\\nModel:\")\n",
    "print(f\"  - Classifier: Support Vector Machine (SVM)\")\n",
    "print(f\"  - Kernel: RBF\")\n",
    "print(f\"  - Best C: {grid_search.best_params_['C']}\")\n",
    "print(f\"  - Best gamma: {grid_search.best_params_['gamma']}\")\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  - Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"  - Precision: {precision*100:.2f}%\")\n",
    "print(f\"  - Recall: {recall*100:.2f}%\")\n",
    "print(f\"  - F1-Score: {f1*100:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All results saved to the 'output' folder.\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
